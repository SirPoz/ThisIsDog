{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e2b295-4de9-4b30-a9a2-fbc8698a38b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T06:16:25.805935300Z",
     "start_time": "2023-10-09T06:16:20.916603500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2df326-5fd6-4491-a6d4-212f720f2077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T06:16:25.877929Z",
     "start_time": "2023-10-09T06:16:25.805935300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Folder': 'Border Collie', 'Count': 112},\n",
       " {'Folder': 'Borzoi', 'Count': 110},\n",
       " {'Folder': 'Cocker', 'Count': 130},\n",
       " {'Folder': 'German Sheperd', 'Count': 109},\n",
       " {'Folder': 'Golden Retriever', 'Count': 127},\n",
       " {'Folder': 'Greyhound', 'Count': 109},\n",
       " {'Folder': 'Pomeranian', 'Count': 149},\n",
       " {'Folder': 'Shiba Inu', 'Count': 98}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"Train\"\n",
    "test_data_dir = \"Test\"\n",
    "\n",
    "# Define data augmentation and normalization transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(degrees=0, shear=30),  # Add shear transformation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Add color jitter\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the train and test data with transformations\n",
    "dataset = ImageFolder(data_dir, transform=train_transform)\n",
    "test_dataset = ImageFolder(test_data_dir, transform=test_transform)\n",
    "\n",
    "# Print some information about the loaded data\n",
    "train_dogs = []\n",
    "pic_count = 0\n",
    "for folder in dataset.classes:\n",
    "    files = os.listdir(os.path.join(data_dir, folder))\n",
    "    train_dogs.append({\"Folder\": folder, \"Count\": len(files)})\n",
    "    pic_count += len(files)\n",
    "\n",
    "print(\"Number of train data:\", pic_count)\n",
    "train_dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a511f3cd-e52c-49db-b09e-434b451895d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T06:16:26.042866600Z",
     "start_time": "2023-10-09T06:16:25.871928700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Data : 844\n",
      "Length of Validation Data : 100\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 32\n",
    "val_size = 100\n",
    "train_size = len(dataset) - val_size \n",
    "\n",
    "train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "print(f\"Length of Validation Data : {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7100780a-9fb4-4bee-a06e-24c33cdd5307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T06:16:26.056126400Z",
     "start_time": "2023-10-09T06:16:25.902930900Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(val_data, batch_size*2, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a3bf1a-f4e9-45c4-90e7-3bfc152160e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T06:16:26.077543300Z",
     "start_time": "2023-10-09T06:16:25.918928600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1681c4-47b3-4abb-b251-c0441df8898a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T06:16:26.079543200Z",
     "start_time": "2023-10-09T06:16:25.943021400Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs] # collect losses for batches\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]    # collect accuracies for batches\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd22b91-12e0-4b80-b7c4-b1948d3c85db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T06:16:26.080543500Z",
     "start_time": "2023-10-09T06:16:25.965373Z"
    }
   },
   "outputs": [],
   "source": [
    "class DogClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200704,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,8)\n",
    "        )\n",
    "        # TODO softmax as activation for output?\n",
    "        # TODO compare architectures:\n",
    "        #  ∘ LeNet-5\n",
    "        #  ∘ AlexNet\n",
    "        #  ∘ VGG-16\n",
    "        #  ∘ Inception-v1\n",
    "        #  ∘ ResNet-50\n",
    "        # resources to read up on architectures:\n",
    "        # https://medium.com/@siddheshb008/lenet-5-architecture-explained-3b559cb2d52b\n",
    "        # https://medium.com/analytics-vidhya/concept-of-alexnet-convolutional-neural-network-6e73b4f9ee30\n",
    "        # https://medium.com/@mygreatlearning/everything-you-need-to-know-about-vgg16-7315defb5918\n",
    "        # https://medium.com/@abheerchrome/inception-v1-architecture-explained-454b2eb66baf\n",
    "        # https://medium.com/@abheerchrome/resnet-architecture-explained-53347e169185\n",
    "        \n",
    "        # more general resources\n",
    "        # https://medium.com/@siddheshb008/why-convolutions-dd7641d2bf81\n",
    "        # https://medium.com/@siddheshb008/understanding-convolution-neural-networks-a30211e12a06\n",
    "        # https://medium.com/@siddheshb008/understanding-convolutional-neural-networks-part-2-98694dd47923\n",
    "        # https://medium.com/@abheerchrome/batch-normalization-explained-1e78f7eb1e8a\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d55718a-8d64-485e-87c6-3d55d27b680f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T06:16:26.081577300Z",
     "start_time": "2023-10-09T06:16:25.992757300Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62ff860-39e8-4a6d-9a1b-e5d8509de678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T07:03:39.343709300Z",
     "start_time": "2023-10-09T06:16:26.009032700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 2.0652, val_loss: 1.9803, val_acc: 0.2700\n",
      "Epoch [1], train_loss: 1.8773, val_loss: 1.7403, val_acc: 0.3038\n",
      "Epoch [2], train_loss: 1.7340, val_loss: 1.5696, val_acc: 0.3958\n",
      "Epoch [3], train_loss: 1.6870, val_loss: 1.5356, val_acc: 0.4115\n",
      "Epoch [4], train_loss: 1.6139, val_loss: 1.6286, val_acc: 0.3819\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.0001\n",
    "model = DogClassification() # number of breeds\n",
    "\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eabc2ed-e016-418e-9813-0c1c81257fba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T07:03:39.356043400Z",
     "start_time": "2023-10-09T07:03:39.321629200Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_func2 = torch.optim.AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12120a4b-7346-48eb-8b0c-ff34120de4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 1.6400, val_loss: 1.5949, val_acc: 0.3958\n",
      "Epoch [1], train_loss: 1.5842, val_loss: 1.5904, val_acc: 0.4436\n",
      "Epoch [2], train_loss: 1.5505, val_loss: 1.4958, val_acc: 0.4488\n",
      "Epoch [3], train_loss: 1.5485, val_loss: 1.4507, val_acc: 0.4870\n",
      "Epoch [4], train_loss: 1.5632, val_loss: 1.4617, val_acc: 0.4314\n"
     ]
    }
   ],
   "source": [
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b53d8e-ea7c-4d86-aa6a-e82a689eb7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
