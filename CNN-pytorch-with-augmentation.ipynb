{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e2b295-4de9-4b30-a9a2-fbc8698a38b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T15:27:52.078869400Z",
     "start_time": "2023-10-08T15:27:46.947704800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2df326-5fd6-4491-a6d4-212f720f2077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T15:27:53.449241700Z",
     "start_time": "2023-10-08T15:27:53.346392300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 944\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'Folder': 'Border Collie', 'Count': 112},\n {'Folder': 'Borzoi', 'Count': 110},\n {'Folder': 'Cocker', 'Count': 130},\n {'Folder': 'German Sheperd', 'Count': 109},\n {'Folder': 'Golden Retriever', 'Count': 127},\n {'Folder': 'Greyhound', 'Count': 109},\n {'Folder': 'Pomeranian', 'Count': 149},\n {'Folder': 'Shiba Inu', 'Count': 98}]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"Train\"\n",
    "test_data_dir = \"Test\"\n",
    "\n",
    "# Define data augmentation and normalization transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(degrees=0, shear=30),  # Add shear transformation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Add color jitter\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the train and test data with transformations\n",
    "dataset = ImageFolder(data_dir, transform=train_transform)\n",
    "test_dataset = ImageFolder(test_data_dir, transform=test_transform)\n",
    "\n",
    "# Print some information about the loaded data\n",
    "train_dogs = []\n",
    "pic_count = 0\n",
    "for folder in dataset.classes:\n",
    "    files = os.listdir(os.path.join(data_dir, folder))\n",
    "    train_dogs.append({\"Folder\": folder, \"Count\": len(files)})\n",
    "    pic_count += len(files)\n",
    "\n",
    "print(\"Number of train data:\", pic_count)\n",
    "train_dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a511f3cd-e52c-49db-b09e-434b451895d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T15:14:04.397133900Z",
     "start_time": "2023-10-08T15:14:04.229510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Data : 844\n",
      "Length of Validation Data : 100\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 32\n",
    "val_size = 100\n",
    "train_size = len(dataset) - val_size \n",
    "\n",
    "train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "print(f\"Length of Validation Data : {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7100780a-9fb4-4bee-a06e-24c33cdd5307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T15:14:04.397133900Z",
     "start_time": "2023-10-08T15:14:04.264057900Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(val_data, batch_size*2, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a3bf1a-f4e9-45c4-90e7-3bfc152160e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T15:14:04.397133900Z",
     "start_time": "2023-10-08T15:14:04.280345Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc1681c4-47b3-4abb-b251-c0441df8898a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T15:14:04.397133900Z",
     "start_time": "2023-10-08T15:14:04.313453Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs] # collect losses for batches\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]    # collect accuracies for batches\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecd22b91-12e0-4b80-b7c4-b1948d3c85db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T15:14:04.405335700Z",
     "start_time": "2023-10-08T15:14:04.337976700Z"
    }
   },
   "outputs": [],
   "source": [
    "class DogClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200704,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,8)\n",
    "        )\n",
    "        # TODO softmax as activation for output?\n",
    "        # TODO compare architectures:\n",
    "        #  ∘ LeNet-5\n",
    "        #  ∘ AlexNet\n",
    "        #  ∘ VGG-16\n",
    "        #  ∘ Inception-v1\n",
    "        #  ∘ ResNet-50\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d55718a-8d64-485e-87c6-3d55d27b680f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T15:14:04.405335700Z",
     "start_time": "2023-10-08T15:14:04.363903500Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ff860-39e8-4a6d-9a1b-e5d8509de678",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-08T15:14:04.388453500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 2138.2061, val_loss: 2.0969, val_acc: 0.1849\n",
      "Epoch [1], train_loss: 2.1347, val_loss: 2.0799, val_acc: 0.0868\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.01\n",
    "model = DogClassification() # number of breeds\n",
    "\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eabc2ed-e016-418e-9813-0c1c81257fba",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
